{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated files: ['C:/Users/stahl-pnordics/OneDrive - SmartStep Consulting GmbH/python/tlv/basis/chapters/Preamble.pdf', 'C:/Users/stahl-pnordics/OneDrive - SmartStep Consulting GmbH/python/tlv/basis/chapters/Chapter_1_Medicinskt_underlag.pdf', 'C:/Users/stahl-pnordics/OneDrive - SmartStep Consulting GmbH/python/tlv/basis/chapters/Chapter_2_Hälsoekonomi.pdf', 'C:/Users/stahl-pnordics/OneDrive - SmartStep Consulting GmbH/python/tlv/basis/chapters/Chapter_3_Resultat.pdf', 'C:/Users/stahl-pnordics/OneDrive - SmartStep Consulting GmbH/python/tlv/basis/chapters/Chapter_4_Budgetpåverkan.pdf', 'C:/Users/stahl-pnordics/OneDrive - SmartStep Consulting GmbH/python/tlv/basis/chapters/Chapter_5_Regler_och_praxis.pdf', 'C:/Users/stahl-pnordics/OneDrive - SmartStep Consulting GmbH/python/tlv/basis/chapters/Chapter_6_Sammanvägning.pdf', 'C:/Users/stahl-pnordics/OneDrive - SmartStep Consulting GmbH/python/tlv/basis/chapters/Chapter_7_Referenser.pdf']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "def find_toc_page(file_path, toc_keyword=\"Innehållsförteckning\"):\n",
    "    \"\"\"\n",
    "    Automatically locate the TOC (table of contents) page in the PDF by searching for a keyword.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the input PDF file.\n",
    "        toc_keyword (str): Keyword to identify the TOC page.\n",
    "\n",
    "    Returns:\n",
    "        int: The page number of the TOC, or -1 if not found.\n",
    "    \"\"\"\n",
    "    # Open the PDF document\n",
    "    doc = fitz.open(file_path)\n",
    "\n",
    "    # Search for the TOC keyword in the document\n",
    "    for page_number in range(len(doc)):\n",
    "        page_text = doc[page_number].get_text(\"text\")\n",
    "        if toc_keyword in page_text:\n",
    "            return page_number\n",
    "\n",
    "    return -1  # Return -1 if TOC page is not found\n",
    "\n",
    "\n",
    "def detect_chapters_with_toc_skip(file_path, toc_page_end):\n",
    "    \"\"\"\n",
    "    Detects chapters in a PDF by skipping TOC and filtering valid chapters.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the input PDF file.\n",
    "        toc_page_end (int): Page number after which to start detecting chapters.\n",
    "\n",
    "    Returns:\n",
    "        dict: Valid chapter titles with their starting pages.\n",
    "    \"\"\"\n",
    "    # Open the PDF document\n",
    "    doc = fitz.open(file_path)\n",
    "\n",
    "    # Define a regex to detect valid chapter headings\n",
    "    chapter_pattern = re.compile(r\"^\\d+\\s+[A-Za-zÅÄÖåäö]+.*$\", re.MULTILINE)\n",
    "\n",
    "    # Detect chapter headings and their start pages\n",
    "    chapter_start_pages = {}\n",
    "    for page_number in range(toc_page_end, len(doc)):  # Skip TOC and earlier pages\n",
    "        page_text = doc[page_number].get_text(\"dict\")\n",
    "        blocks = page_text['blocks']\n",
    "        lines = []\n",
    "        for b in blocks:\n",
    "            if 'lines' in b:\n",
    "                for l in b['lines']:\n",
    "                    for s in l['spans']:\n",
    "                        if s['size']>9:\n",
    "                            lines.append(s['text'])\n",
    "        for line in lines:\n",
    "            match = chapter_pattern.match(line.strip())\n",
    "            if match:\n",
    "                chapter_title = match.group().strip()\n",
    "                # Exclude invalid patterns\n",
    "                if \"Dnr\" not in chapter_title and \"mg\" not in chapter_title:\n",
    "                    if chapter_title not in chapter_start_pages:\n",
    "                        chapter_start_pages[chapter_title] = page_number\n",
    "\n",
    "    # Sequential filtering to ensure correct order\n",
    "    valid_chapters = {}\n",
    "    expected_chapter_number = 1\n",
    "    for chapter, start_page in sorted(chapter_start_pages.items(), key=lambda x: x[1]):\n",
    "        match_number = re.match(r\"^(\\d+)\\s\", chapter)\n",
    "        if match_number:\n",
    "            chapter_number = int(match_number.group(1))\n",
    "            if chapter_number == expected_chapter_number:\n",
    "                valid_chapters[chapter] = start_page\n",
    "                expected_chapter_number += 1\n",
    "\n",
    "    return valid_chapters\n",
    "\n",
    "\n",
    "def ensure_directory_exists(directory_path):\n",
    "    \"\"\"\n",
    "    Ensures that the specified directory exists.\n",
    "    If it doesn't, it will be created.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): Path to the directory.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "\n",
    "\n",
    "def split_preamble_and_chapters_safe(file_path, output_dir, toc_keyword=\"Innehållsförteckning\"):\n",
    "    \"\"\"\n",
    "    Splits the PDF into a preamble and chapter files, ensuring directories exist.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the input PDF file.\n",
    "        output_dir (str): Directory to save the output files.\n",
    "        toc_keyword (str): Keyword to identify the TOC page.\n",
    "\n",
    "    Returns:\n",
    "        list: Paths to the generated files (preamble and chapters).\n",
    "    \"\"\"\n",
    "    # Ensure output directory exists\n",
    "    ensure_directory_exists(output_dir)\n",
    "\n",
    "    # Find the TOC page\n",
    "    toc_page = find_toc_page(file_path, toc_keyword)\n",
    "    if toc_page == -1:\n",
    "        raise ValueError(f\"TOC keyword '{toc_keyword}' not found in the document.\")\n",
    "\n",
    "    # Save the preamble (pages before the TOC)\n",
    "    doc = fitz.open(file_path)\n",
    "    preamble_doc = fitz.open()\n",
    "    preamble_doc.insert_pdf(doc, from_page=0, to_page=toc_page - 1)\n",
    "    preamble_file = f\"{output_dir}/Preamble.pdf\"\n",
    "    preamble_doc.save(preamble_file)\n",
    "    preamble_doc.close()\n",
    "\n",
    "    # Detect valid chapters starting after the TOC\n",
    "    valid_chapters = detect_chapters_with_toc_skip(file_path, toc_page + 1)\n",
    "\n",
    "    # Adjust chapter ranges to handle shared pages\n",
    "    adjusted_chapters = {}\n",
    "    sorted_chapters = sorted(valid_chapters.items(), key=lambda x: x[1])\n",
    "\n",
    "    for i, (chapter_title, start_page) in enumerate(sorted_chapters):\n",
    "        if i < len(sorted_chapters) - 1:\n",
    "            # End at the start of the next chapter, even if it's the same page\n",
    "            _, next_start_page = sorted_chapters[i + 1]\n",
    "            end_page = next_start_page - 1 if next_start_page > start_page else start_page\n",
    "        else:\n",
    "            # Last chapter ends at the last page of the document\n",
    "            end_page = len(doc) - 1\n",
    "        adjusted_chapters[chapter_title] = (start_page, end_page)\n",
    "\n",
    "    # Save each chapter into separate PDF files\n",
    "    output_files = []\n",
    "    for chapter_title, (start_page, end_page) in adjusted_chapters.items():\n",
    "        chapter_doc = fitz.open()\n",
    "        chapter_doc.insert_pdf(doc, from_page=start_page, to_page=end_page)\n",
    "        # Sanitize chapter title for filenames\n",
    "        sanitized_title = re.sub(r\"[^\\w\\s-]\", \"\", chapter_title).strip().replace(\" \", \"_\")\n",
    "        output_file = f\"{output_dir}/Chapter_{sanitized_title}.pdf\"\n",
    "        chapter_doc.save(output_file)\n",
    "        output_files.append(output_file)\n",
    "        chapter_doc.close()\n",
    "\n",
    "    # Return all generated files (preamble first, then chapters)\n",
    "    return [preamble_file] + output_files\n",
    "\n",
    "# Example usage\n",
    "base = 'C:/Users/stahl-pnordics/OneDrive - SmartStep Consulting GmbH/python/tlv/basis/'\n",
    "file_path = base + \"Lynparza 20 okt 2023 1_begransad.pdf\"\n",
    "output_dir = base + \"chapters\"\n",
    "\n",
    "# Split the document into preamble and chapter files\n",
    "generated_files = split_preamble_and_chapters_safe(file_path, output_dir)\n",
    "\n",
    "print(\"Generated files:\", generated_files)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool([''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not bool('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert into trial (\n",
    "    title, \n",
    "    summary, \n",
    "    indication, \n",
    "    meta_analysis, \n",
    "    randomized, \n",
    "    controlled, \n",
    "    type_of_control, \n",
    "    design, \n",
    "    objective, \n",
    "    reference, \n",
    "    blinded, \n",
    "    idanalysis) \n",
    "values (\n",
    "    title 'Läkemedelsbehandling av epilepsi - behandlingsrekommendation',\n",
    "    summary 'This document provides treatment recommendations for epilepsy, emphasizing the importance of individualized treatment based on tolerability and side effect profiles. It suggests that monotherapy should be pursued, with specific drugs recommended based on seizure type.',\n",
    "    indication    'Epilepsi',\n",
    "    meta_analysis    0,\n",
    "    randomized    0,\n",
    "    controlled    0,\n",
    "    type_of_control    '',\n",
    "    design    '',\n",
    "    objective    'efficacy',\n",
    "    reference    'Läkemedelsbehandling av epilepsi - behandlingsrekommendation. Information från Läkemedelsverket 2019;30(3)%(1)s-17.',\n",
    "    blinded    'no',\n",
    "    idanalysis    176) \n",
    "ON DUPLICATE KEY UPDATE \n",
    "reference='Läkemedelsbehandling av epilepsi - behandlingsrekommendation. Information från Läkemedelsverket 2019;30(3)%(1)s-17.',\n",
    "objective='efficacy',\n",
    "title='Läkemedelsbehandling av epilepsi - behandlingsrekommendation',\n",
    "controlled=0,\n",
    "randomized=0,\n",
    "summary='This document provides treatment recommendations for epilepsy, emphasizing the importance of individualized treatment based on tolerability and side effect profiles. \\\n",
    "    It suggests that monotherapy should be pursued, with specific drugs recommended based on seizure type.',\n",
    "blinded='no',\n",
    "idanalysis=176,\n",
    "indication='Epilepsi',\n",
    "meta_analysis=0,\n",
    "design='',\n",
    "type_of_control=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'34000000'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "def fix_numbers(raw):\n",
    "    raw = re.sub('million', '000000', raw, flags=re.I)\n",
    "    raw = re.sub('thousand', '000', raw, flags=re.I)\n",
    "    raw = re.sub('[\\.\\,]', '', raw)\n",
    "    raw = re.sub(' ', '', raw) \n",
    "    if re.search('\\d*', raw):\n",
    "        raw = re.search('[\\d]*', raw)[0]\n",
    "    return raw\n",
    "\n",
    "fix_numbers('3.4 million SEK')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
